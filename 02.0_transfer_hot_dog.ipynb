{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Practicum AI Logo image](https://github.com/PracticumAI/practicumai.github.io/blob/main/images/logo/PracticumAI_logo_250x50.png?raw=true)\n",
    "***\n",
    "# *Practicum AI:* Keras Transfer Learning\n",
    "This exercise adapted from Krohn, J. and Beyleveld, G (2020) <i>Deep Learning Illustrated: A Visual, Interactive Guide to Artificial Intelligence </i> from <a href=\"https://github.com/the-deep-learners/deep-learning-illustrated/blob/master/notebooks/transfer_learning_in_keras.ipynb\">Pearson Education</a> (Transfer Learning, Chapter 10).\n",
    "\n",
    "In this notebook, we cover how to load a pre-trained model (VGGNet19) and finetune it for a new task: detecting hot dogs.\n",
    "\n",
    "<p float=\"left\">\n",
    "  <img src=\"images/hot_dog.png\" width=\"250\" height=\"250\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dependencies\n",
    "\n",
    "Import the supporting libraries and VGG19 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the pre-trained VGG19 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vgg19 = VGG19(include_top = False,\n",
    "              weights     = 'imagenet',\n",
    "              input_shape = (224,224,3),\n",
    "              pooling     = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Freeze all the layers in the base VGGNet19 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for layer in vgg19.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add custom classification layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate the sequential model and add the VGG19 model: \n",
    "model = Sequential()\n",
    "model.add(vgg19)\n",
    "\n",
    "# Add the custom layers atop the VGG19 model: \n",
    "model.add(Flatten(name = 'flattened'))\n",
    "model.add(Dropout(0.5, name = 'dropout'))\n",
    "model.add(Dense(2, activation = 'softmax', name = 'predictions'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acquire the dataset from this [location](https://www.kaggle.com/dansbecker/hot-dog-not-hot-dog/home).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate two image generator classes:\n",
    "train_datagen       = ImageDataGenerator(\n",
    "    rescale         = 1.0/255,\n",
    "    data_format     = 'channels_last',\n",
    "    rotation_range  = 30,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode       = 'reflect')\n",
    "\n",
    "valid_datagen   = ImageDataGenerator(\n",
    "    rescale     = 1.0/255,\n",
    "    data_format = 'channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the batch size:\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add documentation here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 499 images belonging to 2 classes.\n",
      "Found 500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define the train and validation generators: \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory   = './data/train',\n",
    "    target_size = (224, 224),\n",
    "    classes     = ['hot_dog','not_hot_dog'],\n",
    "    class_mode  = 'categorical',\n",
    "    batch_size  = batch_size,\n",
    "    shuffle     = True,\n",
    "    seed        = 42)\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    directory   = './data/test',\n",
    "    target_size = (224, 224),\n",
    "    classes     = ['hot_dog','not_hot_dog'],\n",
    "    class_mode  = 'categorical',\n",
    "    batch_size  = batch_size,\n",
    "    shuffle     = True,\n",
    "    seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/47771489/ipykernel_23690/2169329564.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(train_generator, steps_per_epoch=15,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 16:38:36.652277: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2022-09-22 16:38:37.586112: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2022-09-22 16:38:37.693303: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: ptxas exited with non-zero error code 32512, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/15 [=>............................] - ETA: 59s - loss: 0.9510 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 16:38:39.339485: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 12s 543ms/step - loss: 0.9994 - accuracy: 0.5503 - val_loss: 0.7683 - val_accuracy: 0.5979\n",
      "Epoch 2/16\n",
      "15/15 [==============================] - 7s 453ms/step - loss: 0.5931 - accuracy: 0.7173 - val_loss: 0.4672 - val_accuracy: 0.7750\n",
      "Epoch 3/16\n",
      "15/15 [==============================] - 7s 455ms/step - loss: 0.4813 - accuracy: 0.7580 - val_loss: 0.5778 - val_accuracy: 0.7188\n",
      "Epoch 4/16\n",
      "15/15 [==============================] - 7s 481ms/step - loss: 0.3919 - accuracy: 0.8180 - val_loss: 0.4226 - val_accuracy: 0.7958\n",
      "Epoch 5/16\n",
      "15/15 [==============================] - 7s 458ms/step - loss: 0.4212 - accuracy: 0.7987 - val_loss: 0.6792 - val_accuracy: 0.7104\n",
      "Epoch 6/16\n",
      "15/15 [==============================] - 7s 455ms/step - loss: 0.4130 - accuracy: 0.8180 - val_loss: 0.5876 - val_accuracy: 0.7521\n",
      "Epoch 7/16\n",
      "15/15 [==============================] - 7s 453ms/step - loss: 0.3869 - accuracy: 0.8266 - val_loss: 0.4716 - val_accuracy: 0.7896\n",
      "Epoch 8/16\n",
      "15/15 [==============================] - 7s 473ms/step - loss: 0.3193 - accuracy: 0.8501 - val_loss: 0.5423 - val_accuracy: 0.7542\n",
      "Epoch 9/16\n",
      "15/15 [==============================] - 7s 448ms/step - loss: 0.2948 - accuracy: 0.8651 - val_loss: 0.5322 - val_accuracy: 0.7812\n",
      "Epoch 10/16\n",
      "15/15 [==============================] - 7s 462ms/step - loss: 0.2547 - accuracy: 0.8865 - val_loss: 0.5256 - val_accuracy: 0.7833\n",
      "Epoch 11/16\n",
      "15/15 [==============================] - 7s 449ms/step - loss: 0.2911 - accuracy: 0.8672 - val_loss: 0.4448 - val_accuracy: 0.7937\n",
      "Epoch 12/16\n",
      "15/15 [==============================] - 7s 454ms/step - loss: 0.2410 - accuracy: 0.8951 - val_loss: 0.5277 - val_accuracy: 0.7833\n",
      "Epoch 13/16\n",
      "15/15 [==============================] - 7s 449ms/step - loss: 0.2386 - accuracy: 0.8994 - val_loss: 0.5870 - val_accuracy: 0.7479\n",
      "Epoch 14/16\n",
      "15/15 [==============================] - 7s 450ms/step - loss: 0.2592 - accuracy: 0.8972 - val_loss: 0.4876 - val_accuracy: 0.7937\n",
      "Epoch 15/16\n",
      "15/15 [==============================] - 7s 454ms/step - loss: 0.2295 - accuracy: 0.9058 - val_loss: 0.5167 - val_accuracy: 0.7771\n",
      "Epoch 16/16\n",
      "15/15 [==============================] - 7s 450ms/step - loss: 0.2610 - accuracy: 0.8929 - val_loss: 0.7810 - val_accuracy: 0.7188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2baa5e442fa0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch = 15, \n",
    "                    epochs = 16, validation_data = valid_generator, \n",
    "                    validation_steps = 15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.7.0",
   "language": "python",
   "name": "tensorflow-2.7.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
